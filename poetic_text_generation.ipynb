{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"iDDh0OCEL9U9"},"outputs":[],"source":["import random\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import RMSprop\n","from tensorflow.keras.layers import Activation, Dense, LSTM"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1711894570032,"user":{"displayName":"Saai Smriti S","userId":"13152717399814648246"},"user_tz":-330},"id":"-8cGVIhj2a_6","outputId":"d01d6332-4b19-4935-c0f1-c36812a65738"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n","1115394/1115394 [==============================] - 0s 0us/step\n"]}],"source":["filepath = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YhrtU0Rn2l9X"},"outputs":[],"source":["text = open(filepath, 'rb')\\\n","    .read().decode(encoding='utf-8').lower()\n","text = text[300000:800000]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3pUHCvaC2mu1"},"outputs":[],"source":["characters = sorted(set(text))\n","char_to_index = dict((c, i) for i, c in enumerate(characters))\n","index_to_char = dict((i, c) for i, c in enumerate(characters))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vqIbhGvs2t3x"},"outputs":[],"source":["SEQ_LENGTH = 40\n","STEP_SIZE = 3\n","sentences = []\n","next_char = []"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3bNCZsxE2vZG"},"outputs":[],"source":["for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n","    sentences.append(text[i: i + SEQ_LENGTH])\n","    next_char.append(text[i + SEQ_LENGTH])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wv1hiNpM2vVt"},"outputs":[],"source":["x = np.zeros((len(sentences), SEQ_LENGTH,\n","              len(characters)), dtype=bool)\n","y = np.zeros((len(sentences),\n","              len(characters)), dtype=bool)\n","\n","for i, satz in enumerate(sentences):\n","    for t, char in enumerate(satz):\n","        x[i, t, char_to_index[char]] = 1\n","    y[i, char_to_index[next_char[i]]] = 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t19eROS_2vS3"},"outputs":[],"source":["model = Sequential()\n","model.add(LSTM(128,\n","               input_shape=(SEQ_LENGTH,\n","                            len(characters))))\n","model.add(Dense(len(characters)))\n","model.add(Activation('softmax'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":444588,"status":"ok","timestamp":1711895024507,"user":{"displayName":"Saai Smriti S","userId":"13152717399814648246"},"user_tz":-330},"id":"iTl4SHoB2vP8","outputId":"fba78792-7777-4c58-93bb-d18e9c494d9a"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/4\n","651/651 [==============================] - 107s 162ms/step - loss: 2.7031\n","Epoch 2/4\n","651/651 [==============================] - 105s 162ms/step - loss: 2.3111\n","Epoch 3/4\n","651/651 [==============================] - 107s 164ms/step - loss: 2.1933\n","Epoch 4/4\n","651/651 [==============================] - 105s 161ms/step - loss: 2.1098\n"]},{"data":{"text/plain":["<keras.src.callbacks.History at 0x799804a66800>"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["model.compile(loss='categorical_crossentropy',\n","              optimizer=RMSprop(lr=0.01))\n","\n","model.fit(x, y, batch_size=256, epochs=4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b-eFW83_2uuQ"},"outputs":[],"source":["def sample(preds, temperature=1.0):\n","    preds = np.asarray(preds).astype('float64')\n","    preds = np.log(preds) / temperature\n","    exp_preds = np.exp(preds)\n","    preds = exp_preds / np.sum(exp_preds)\n","    probas = np.random.multinomial(1, preds, 1)\n","    return np.argmax(probas)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sc0haqlmMHU6"},"outputs":[],"source":["def generate_text(length, temperature):\n","    start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n","    generated = ''\n","    sentence = text[start_index: start_index + SEQ_LENGTH]\n","    generated += sentence\n","    for i in range(length):\n","        x_predictions = np.zeros((1, SEQ_LENGTH, len(characters)))\n","        for t, char in enumerate(sentence):\n","            x_predictions[0, t, char_to_index[char]] = 1\n","\n","        predictions = model.predict(x_predictions, verbose=0)[0]\n","        next_index = sample(predictions,\n","                                 temperature)\n","        next_character = index_to_char[next_index]\n","\n","        generated += next_character\n","        sentence = sentence[1:] + next_character\n","    return generated"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"ss7GTsmQ3DrD","outputId":"d5acf97e-3091-416b-9237-38c60fdb73c7"},"outputs":[{"name":"stdout","output_type":"stream","text":["----------0.2--------\n",":\n","they must take it in sense that feel in the mand cound his the her the beand the will he sine the mare the the beather and with the cound my mere the will the me the his not be the with the sount the will with the corend the will and and in the proust the mere the will and i to the more the broon the with the the beren the count of the \n","\n","----------0.4--------\n"," would it do you good.\n","\n","queen:\n","and i coullo to the andenow to be mander,\n","and the more the will of the be the hing,\n","row the sonde thit or beaty a dome and the frome that thour hare the bery ant here or beard.\n","\n","king my the maye, ous the sour of cour our and it the brither foll with the hart, the beath, ware the king the will the brout this \n","\n","----------0.5--------\n","all you this night\n","inherit at my house; the ir thas to hing and ath be this the roris the tous thall will sine shat not and and ald and in the cound,\n","the maren to ard and in the pouren the tore the beaing no tour of ance mand curene.\n","\n","lllout:\n","i wathy sise dot her is the mant to mere of mein hor tooke, hard here the been thin thith ur with\n","\n","----------0.6--------\n",":\n","do not swear at all;\n","or, if thou wilt, is dofer and right thee bordonge thes some the aldse mant be the wared,\n","the ware will thee and not it my o proull the there werd with arken,\n","whes of his i couce and i sound tho ke het if wither our nowh the cament,\n","and the gade so no no thou thatse.\n","\n","ondere:\n","i with hat sees, a to this is my ur i ma\n","\n","----------0.7--------\n","u are a lover; borrow cupid's wings,\n","and dowith, io not gual id whaith ther teme.\n","\n","cond, ie lief and it rich as a astive of the hile be the wrorcos, i thet no tee,\n","i geare of yours yous, the preay and me lous on, af noury fit so daded or mats the aingers'd cupe to ensinp and in that kish withing of it i me poult ke thay the lood seard i h\n","\n","----------0.8--------\n","\n","yet can i not of such tame patience boan\n","there my sorlo thou marery ane the hing his foard\n","thou foret dowe no ghath you hill whive ?all, i do thet henrer ham here walce that or southere.\n","\n","whill this parke\n","to good, byallow thou hmy vet,\n","no dour come, wit nowh you i will of in shelly wardenot gek,\n","and oul how nore of to forch you thry mast\n"]}],"source":["print(\"----------0.2--------\")\n","print(generate_text(300, 0.2))\n","print(\"\\n----------0.4--------\")\n","print(generate_text(300, 0.4))\n","print(\"\\n----------0.5--------\")\n","print(generate_text(300, 0.5))\n","print(\"\\n----------0.6--------\")\n","print(generate_text(300, 0.6))\n","print(\"\\n----------0.7--------\")\n","print(generate_text(300, 0.7))\n","print(\"\\n----------0.8--------\")\n","print(generate_text(300, 0.8))"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN1IsRY4DvHx5ojSUa8gy0m"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}